{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration Setup Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created on Thu Dec  5 11:47:31 2019\n",
    "\n",
    "@author: williamstanford"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This script enables you to capture images that you can use to calibrate your camera\n",
    "\n",
    "Things to keep in mind\n",
    "    1. Plan ahead when condsidering your real world coordinate system\n",
    "        - moving something from one peg to another is approximately 25.4mm \n",
    "        - with our micromanipulator, you have approximately 40 milimeters of horizontal freedom\n",
    "            and 30 milimeters of vertical freedom\n",
    "    2. regular increments make it easier to tell if you're off or missed a picture\n",
    "        - Suggestions - 5, 8, or 10mm horizontally, 5, or 10mm vertically\n",
    "    3. Save your planned real coordinates as an ods file with the X,Y,Z coordinates\n",
    "        - see realPoints.ods as an example. \n",
    "        - make sure you have a space between the beginning of your cooridnates and the \n",
    "             top of the ods sheet\n",
    "    3. Make sure to note the order of your cameras at this stage - you need to keep\n",
    "        this consistent in later parts of processing\n",
    "        \n",
    "Before running, you may need to start up your cameras by running the following code in terminal/command line:\n",
    "\n",
    "conda activate pseye\n",
    "sudo chmod o+w /dev/bus/usb/001/*\n",
    "sudo chmod o+w /dev/bus/usb/002/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Calibration Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pseyepy import Camera, Display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "path = '/home/nel-lab/Documents/Behavior3D'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, set num_cameras to the number of cameras you have connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No camera available at index 0.\nAvailable cameras: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a9e22ebaa139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m            \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_cameras\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m            \u001b[0mresolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRES_LARGE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_cameras\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m            colour=[False]*num_cameras)\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/pseye/lib/python3.7/site-packages/pseyepy/cameras.pyx\u001b[0m in \u001b[0;36mpseyepy.cameras.Camera.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: No camera available at index 0.\nAvailable cameras: 0"
     ]
    }
   ],
   "source": [
    "num_cameras = 3\n",
    "c = Camera(list(range(3)), \n",
    "           fps=[70]*num_cameras, \n",
    "           resolution=[Camera.RES_LARGE]*num_cameras, \n",
    "           colour=[False]*num_cameras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the cameras are displaying properly, with the correct orientation, run the following code to open, then close the display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Display(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the movie. Set the number of frames to however many points you need for calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, timestamps = c.read()\n",
    "frame_size = frames[0].shape\n",
    "num_frames = 10\n",
    "mov = np.zeros([num_frames, num_cameras, frame_size[0], frame_size[1]], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the calibration tool to your preferred start position, then run the following code. After pressing enter, adjust the calibration tool to the next position. \n",
    "\n",
    "You may wish to create a .csv or Excel file titled \"real_coordinates.ods\" with x, y, z as headers and the millimeters you plan to move the calibration tool planned out. Follow this when calibrating to avoid confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_frames): \n",
    "    frames, timestamps = c.read()\n",
    "    frames, timestamps = c.read()\n",
    "    mov[i] = np.array(frames)\n",
    "    plt.imshow(mov[i,1,:,:])\n",
    "    plt.title(\"Calibration point \" + str(i))\n",
    "    plt.pause(0.001)\n",
    "    input(\"Press enter to view image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the order of cameras by running the code below and recording which index number corresponds to which camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camera in range(num_cameras):\n",
    "    plt.imshow(mov[i,camera,:,:])\n",
    "    plt.title(\"Camera \" + str(camera)+\", Image \" + str(i))    \n",
    "    plt.pause(0.001)\n",
    "    input(\"Press enter to continue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_cameras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-621f3a89bf56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbase_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'recal_3_cam_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'0.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2.npz'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npz'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cameras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_cameras' is not defined"
     ]
    }
   ],
   "source": [
    "base_name = 'recal_3_cam_'\n",
    "filenames = [str(i)+'.npz' for i in range(num_cameras)]\n",
    "\n",
    "for index,fls in enumerate(filenames):\n",
    "    np.savez(\"mov_\" + base_name + fls, movie = mov[:,index,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the cameras to end the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Calibration Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from pandas_ods_reader import read_ods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you will be labeling the same point from different camera views, so that the algorithm can align these images to get an idea of the 3D space. First, run the cell below to set up the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_images(start, end, views, obstructed_images, root_directory, video_name, realPoints):\n",
    "        \n",
    "    os.chdir(root_directory)\n",
    "    images = end - start - len(obstructed_images)\n",
    "    coords = np.zeros((images+1, 2*len(views)))\n",
    "    \n",
    "    for j in range(len(views)):\n",
    "        path = 'images_for_' + video_name + views[j]\n",
    "        os.chdir(path)\n",
    "        \n",
    "        p = 0\n",
    "        for k in range(int(end-start)):\n",
    "            i = k+start\n",
    "            if (np.isin(i, obstructed_images) == False):\n",
    "                image = plt.imread('fr_'+str(i).zfill(5)+'.png')\n",
    "                plt.figure(1, figsize=(20,20))\n",
    "                plt.imshow(image, cmap='gray')\n",
    "                plt.title('image ' + str(i).zfill(5) + ' cam ' + views[j])\n",
    "                s1 = 2*j\n",
    "                s2 = s1+2              \n",
    "                coords[p,s1:s2] = plt.ginput(1)[0] \n",
    "                p = p+1\n",
    "     \n",
    "        # bug where first image is double counted, so we built an array with 1\n",
    "        # extra row index, here we fill this row with the pts from the final image\n",
    "        i = end-1          \n",
    "        image = plt.imread('fr_'+str(i).zfill(5)+'.png')\n",
    "        plt.figure(1, figsize=(20,20))\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title('image ' + str(i).zfill(5) + ' cam ' + views[j])\n",
    "        s1 = 2*j\n",
    "        s2 = s1+2\n",
    "        coords[-1,s1:s2] = plt.ginput(1)[0] \n",
    "\n",
    "        i = 0\n",
    "                    \n",
    "        plt.close()            \n",
    "        os.chdir(root_directory)\n",
    "    \n",
    "    coords_no_duplicates = pd.DataFrame(coords[1:,:])\n",
    "\n",
    "    '''\n",
    "    Process real points from ods or excel, this code will automatically remove\n",
    "    rows before the starting image, after the ending image, and rows corresponding \n",
    "    to images obstructed\n",
    "    '''\n",
    "    \n",
    "    real = pd.DataFrame([])\n",
    "    zeros = pd.DataFrame([[0,0,0]], columns=[\"X\", \"Y\", \"Z\"])\n",
    "    rp = read_ods(realPoints,1, columns=[\"X\", \"Y\", \"Z\"])\n",
    "    # rp = pd.read_excel('realPoints.xlsx') # if pulling points from an excel file\n",
    "    real = zeros.append(rp)\n",
    "    real.reset_index(inplace = True, drop = True) \n",
    "    \n",
    "    real = real.drop(real.index[end:])\n",
    "    real = real.drop(real.index[0:start])\n",
    "    \n",
    "    k = 0  \n",
    "    i = 0\n",
    "    for i in range(real.shape[0]):\n",
    "        for j in range(len(obstructed_images)):    \n",
    "            if real.index[i-k] == obstructed_images[j]:          \n",
    "                real = real.drop(real.index[i-k])\n",
    "                k = k+1\n",
    "    \n",
    "    real.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    '''\n",
    "    Add the two dataframes together\n",
    "    '''\n",
    "    coords_and_realPoints = pd.DataFrame([])\n",
    "    coords_and_realPoints = coords_and_realPoints.append(coords_no_duplicates)\n",
    "    coords_and_realPoints['X'] = real['X']\n",
    "    coords_and_realPoints['Y'] = real['Y']\n",
    "    coords_and_realPoints['Z'] = real['Z']\n",
    "                \n",
    "    return coords_and_realPoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are 3 potential models.\n",
    "\n",
    "Model 1 and 2: For 3 views. m1_end indicates the number of frames you have from one camera. realPointsPath is the path to your excel file with your list of what coordinates you photographed. For the variable m1_obstructed images, go through all of the images from each camera and note the frame number for any images where you can't see the calibration tool, as these will have to be omitted from the model. m1_views refers to the cameras you'd like to use to create hte 3D view: just list the number of the camera from the previous steps.\n",
    "\n",
    "Models 2a and 2b have very similar variables as Model 1 and 2; however, they only accept two camera views.\n",
    "\n",
    "Make sure you click on the same (x, y, z) position each time, or the labeling will be inaccurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for model 1\n",
    "'''\n",
    "root_directory = '/home/nel-lab/Documents/Behavior3D/Videos'\n",
    "os.chdir(root_directory)\n",
    "realPointsPath = '/home/nel-lab/Desktop/Cynthia/real_coordinates.ods'\n",
    "\n",
    "video_name = 'mov_mov_recal_3_cam_'\n",
    "\n",
    "m1_start = 0\n",
    "m1_end = 10\n",
    "m1_obstructed_images = []\n",
    "m1_views = ['0','1','2'] # Cameras - front left, front right, bot\n",
    "\n",
    "coords_m1 = label_images(m1_start, m1_end, m1_views, m1_obstructed_images, root_directory, \n",
    "                         video_name, realPointsPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to save your 3D coordinates as a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coords_m1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b2d24f9cce7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_1_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoords_m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_1_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1_coordinates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_1_coordinates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/nel-lab/Desktop/Cynthia/model_1_coordinates.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'coords_m1' is not defined"
     ]
    }
   ],
   "source": [
    "model_1_coordinates = coords_m1\n",
    "model_1_coordinates = pd.DataFrame(model_1_coordinates)\n",
    "model_1_coordinates.to_csv('/home/nel-lab/Desktop/Cynthia/model_1_coordinates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for model 2 - this requires that all three cameras saw every position \n",
    "this wasn't the case for the most recent setup with 5 cameras on the wheel\n",
    "you'll have to use a separate 2-camera models each of the back feet - these\n",
    "models are 2a and 2b\n",
    "'''\n",
    "root_directory = '/home/nel-lab/Desktop/WS_tests_for_DLC2/calibration2/Calibration_Videos2'\n",
    "os.chdir(root_directory)\n",
    "realPointsPath = '/home/nel-lab/Desktop/WS_tests_for_DLC2/calibration2/realPoints.ods'\n",
    "\n",
    "video_name = 'mov_recal_5_cam_'\n",
    "\n",
    "m2_start = 15\n",
    "m2_end = 70\n",
    "m2_obstructed_images = [69,60,59,20,19]\n",
    "m2_views = ['1','3','4'] # Cameras - back left, back right, bot\n",
    "\n",
    "coords_m2 = label_images(m2_start, m2_end, m2_views, m2_obstructed_images, root_directory, \n",
    "                         video_name, realPointsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_coordinates = coords_m2\n",
    "model_2_coordinates = pd.DataFrame(model_2_coordinates)\n",
    "model_2_coordinates.to_csv('/home/nel-lab/Desktop/WS_tests_for_DLC2/calibration2/model_2_coordinates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for model 2a\n",
    "'''\n",
    "root_directory = '/home/nel-lab/Desktop/WS_tests_for_DLC2/calibration2/Calibration_Videos2'\n",
    "os.chdir(root_directory)\n",
    "realPointsPath = '/home/nel-lab/Desktop/WS_tests_for_DLC2/calibration2/realPoints.ods'\n",
    "\n",
    "video_name = 'mov_recal_5_cam_'\n",
    "\n",
    "m2a_start = 15\n",
    "m2a_end = 70\n",
    "m2a_obstructed_images = [69,60,59,20,19]\n",
    "m2a_views = ['1','4'] # camera's - back left and bottom\n",
    "\n",
    "coords_m2a = label_images(m2a_start, m2a_end, m2a_views, m2a_obstructed_images, root_directory, video_name, realPointsPath)\n",
    "\n",
    "model_2a_coordinates = coords_m2a\n",
    "model_2a_coordinates = pd.DataFrame(model_2a_coordinates)\n",
    "model_2a_coordinates.to_csv('/home/nel-lab/Desktop/WS_tests_for_DLC2/calibration2/model_2a_coordinates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "'''\n",
    "for model 2b\n",
    "'''\n",
    "root_directory = '/home/nel-lab/Desktop/WS_tests_for_DLC2/calibration2/Calibration_Videos2'\n",
    "os.chdir(root_directory)\n",
    "realPointsPath = '/home/nel-lab/Desktop/WS_tests_for_DLC2/calibration2/realPoints.ods'\n",
    "\n",
    "video_name = 'mov_recal_5_cam_'\n",
    "\n",
    "m2b_start = 15\n",
    "m2b_end = 70\n",
    "m2b_obstructed_images = [69,60,59,20,19]\n",
    "m2b_views = ['3','4'] # camera's - back right and bottom\n",
    "\n",
    "coords_m2b = label_images(m2b_start, m2b_end, m2b_views, m2b_obstructed_images, root_directory, video_name, realPointsPath)\n",
    "\n",
    "#%%\n",
    "model_2b_coordinates = coords_m2b\n",
    "model_2b_coordinates = pd.DataFrame(model_2b_coordinates)\n",
    "model_2b_coordinates.to_csv('/home/nel-lab/Desktop/WS_tests_for_DLC2/calibration2/model_2b_coordinates.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a 3D structure from DeepLabCut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Mon Dec  9 14:43:03 2019\n",
    "\n",
    "@author: williamstanford\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "path = '/home/nel-lab/Documents/Behavior3D/Videos/calibration_apr'\n",
    "\n",
    "os.chdir(path)\n",
    "rootDirectory = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary functions\n",
    "def Build_Model(coordinatePath):\n",
    "    \n",
    "    ''' \n",
    "    uses the location of your calibration points in the real world and fits a polynomial \n",
    "    to this data to project the pixel locations in each image to your real world coordinate system\n",
    "    '''  \n",
    "    \n",
    "    All_Data = pd.read_csv(coordinatePath) \n",
    "    \n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split( \n",
    "            All_Data.iloc[:,:-3], All_Data.iloc[:,-3:], random_state=42,  test_size = 0.25)\n",
    "    \n",
    "#    v = All_Data.shape[0]//2\n",
    "#    X_valid, X_train = X_train_full[:v], X_train_full[v:]\n",
    "#    y_valid, y_train = y_train_full[:v], y_train_full[v:]\n",
    "    \n",
    "    svm = SVR(kernel=\"poly\", degree=2, C=1500, epsilon=0.01, gamma=\"scale\")\n",
    "    regr = MultiOutputRegressor(svm)\n",
    "    regr.fit(X_train_full, y_train_full)\n",
    "    \n",
    "    test_predictions = regr.predict(X_test)\n",
    "    test_MSE = mean_squared_error(test_predictions, y_test)\n",
    "    print('Test MSE: ' + str(test_MSE))\n",
    "    \n",
    "    X = All_Data.iloc[:,:-3]\n",
    "    Y = All_Data.iloc[:,-3:]\n",
    "    \n",
    "    CV_predictions = cross_val_predict(regr, X, Y, cv=10)\n",
    "    MSE = mean_squared_error(CV_predictions, Y)\n",
    "    \n",
    "    print('Mean squared error: ' + str(MSE))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for x in range(CV_predictions.shape[0]):\n",
    "        ax.scatter(CV_predictions[x,0], CV_predictions[x,1], CV_predictions[x,2], \n",
    "                   color = 'blue')\n",
    "        ax.scatter(All_Data.iloc[x,-3], All_Data.iloc[x,-2], All_Data.iloc[x,-1], \n",
    "                   color = 'red')\n",
    "\n",
    "    return regr, X, Y, CV_predictions\n",
    "\n",
    "def PreProcess_DLC_data(df):\n",
    "    \n",
    "    '''\n",
    "    We preprocess the CSV's output by DeepLabCut\n",
    "        1. Rename each column with the bodypart and coordinate (x or y)\n",
    "        2. delete redundant rows and columns \n",
    "    '''\n",
    "    \n",
    "    for y in range (df.shape[1]):        \n",
    "        df.rename(columns={df.columns[y]:df.iloc[0,y]+'_'+df.iloc[1,y]}, inplace=True)\n",
    "        \n",
    "    df2 = df.iloc[2:,1:]\n",
    "    \n",
    "    li_columns = [col for col in df2.columns if 'likelihood' in col]\n",
    "    df2 = df2.drop(columns=li_columns)\n",
    "        \n",
    "    return df2\n",
    "\n",
    "'''\n",
    "need to make sure that columns in each dataframe align correctly. These two\n",
    "functions enable us to compare columns in two dataframes and delete the extra \n",
    "'''\n",
    "    \n",
    "def Diff(li1, li2):\n",
    "        return (list(set(li1) - set(li2)))\n",
    "    \n",
    "def Standardize_columns(df1,df2):\n",
    "    cols1 = df1.columns.tolist()\n",
    "    cols2 = df2.columns.tolist()\n",
    "    \n",
    "    col_diff = Diff(cols1,cols2)\n",
    "    \n",
    "    for i in range(len(col_diff)):\n",
    "        if col_diff[i] in df1.columns:\n",
    "            df1 = df1.drop(columns=col_diff[i])\n",
    "        if col_diff[i] in df2.columns:\n",
    "            df2 = df2.drop(columns=col_diff[i])\n",
    "            \n",
    "    return df1,df2\n",
    "\n",
    "def Predict_Real_Coordinates(df1, df2, df3, bodyparts, numCameras, regr):\n",
    "    print(df1.shape, df2.shape, df3.shape)\n",
    "    \n",
    "    # make sure all dataframes share the same columns and delete extras\n",
    "    df1,df2 = Standardize_columns(df1,df2)\n",
    "    df2,df3 = Standardize_columns(df2,df3)\n",
    "    \n",
    "    # reorder columns to follow order of the first dataframe\n",
    "    df2 = df2[df1.columns]\n",
    "    df3 = df3[df1.columns]\n",
    "    \n",
    "    print(df1.shape, df2.shape, df3.shape)\n",
    "\n",
    "    '''\n",
    "    Use model and data generated by DeepLabCut to predict the 3D locations of every\n",
    "    bodypart of interest\n",
    "    '''  \n",
    "    rows = df1.shape[0]\n",
    "    columns = 2*numCameras\n",
    "    bparts = bodyparts\n",
    "    \n",
    "    test_data = np.zeros((rows, columns*bparts))\n",
    "    print(test_data.shape, df1.shape)\n",
    "    \n",
    "    for r in range(bparts):\n",
    "        test_data[:,6*r] = df1.iloc[:,2*r]\n",
    "        test_data[:,6*r+1] = df1.iloc[:,2*r+1]\n",
    "        \n",
    "        test_data[:,6*r+2] = df2.iloc[:,2*r]\n",
    "        test_data[:,6*r+3] = df2.iloc[:,2*r+1]\n",
    "        \n",
    "        test_data[:,6*r+4] = df3.iloc[:,2*r]\n",
    "        test_data[:,6*r+5] = df3.iloc[:,2*r+1]\n",
    "    \n",
    "    Predictions = np.zeros((rows,3*bparts))\n",
    "    \n",
    "    for i in range(bparts):\n",
    "        Predictions[:,3*i:(3*i+3)] = regr.predict(test_data[:,6*i:(6*i+6)])\n",
    "        \n",
    "    return Predictions\n",
    "\n",
    "def Predict_Real_Coordinates_2cam(df1, df2, bodyparts, numCameras, regr):\n",
    "    \n",
    "    # make sure all dataframes share the same columns and delete extras\n",
    "    df1,df2 = Standardize_columns(df1,df2)\n",
    "    print(df1.shape, df2.shape)\n",
    "    \n",
    "    # reorder columns to follow order of the first dataframe\n",
    "    df2 = df2[df1.columns]\n",
    "    \n",
    "    '''\n",
    "    Use model and data generated by DeepLabCut to predict the 3D locations of every\n",
    "    bodypart of interest\n",
    "    '''\n",
    "        \n",
    "    rows = df1.shape[0]\n",
    "    columns = 2*numCameras\n",
    "    bparts = bodyparts\n",
    "    \n",
    "    test_data = np.zeros((rows, columns*bparts))\n",
    "    \n",
    "    for r in range(bparts):\n",
    "        test_data[:,4*r] = df1.iloc[:,2*r]\n",
    "        test_data[:,4*r+1] = df1.iloc[:,2*r+1]\n",
    "        \n",
    "        test_data[:,4*r+2] = df2.iloc[:,2*r]\n",
    "        test_data[:,4*r+3] = df2.iloc[:,2*r+1]\n",
    "\n",
    "    Predictions = np.zeros((rows,3*bparts))\n",
    "    \n",
    "    for i in range(bparts):\n",
    "        Predictions[:,3*i:(3*i+3)] = regr.predict(test_data[:,4*i:(4*i+4)])\n",
    "        \n",
    "    return Predictions\n",
    "\n",
    "def Plot_Bodyparts(Predictions, bodyparts):\n",
    "    \n",
    "    bparts = bodyparts    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    for y in range(300):\n",
    "    # for y in range(Predictions.shape[0]): # to plot full video\n",
    "        plt.cla()\n",
    "        for x in range(bparts):\n",
    "            i = 3*x\n",
    "            j = 3*x+1\n",
    "            k = 3*x+2\n",
    "            z = 2900\n",
    "            ax.scatter(Predictions[z+y,i], Predictions[z+y,j], \n",
    "                       Predictions[z+y,k], color = 'blue')\n",
    "#            ax.set_xlim([0,40])\n",
    "#            ax.set_ylim([0,60])\n",
    "#            ax.set_zlim([-20,15])\n",
    "            ax.set_xlim([-130,-60])\n",
    "            ax.set_ylim([-1,1])\n",
    "            ax.set_zlim([-5,20])\n",
    "            \n",
    "        plt.pause(0.01)\n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process the DeepLabCut CSV for formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_left = pd.read_csv('csv files/front_left_0411.csv') # The name here has been edited - these files are from the output of DLC after analyzing a video                  \n",
    "front_right = pd.read_csv('csv files/front_right_0411.csv') \n",
    "bot = pd.read_csv('csv files/bot_0411.csv')\n",
    "\n",
    "mod_front_left = PreProcess_DLC_data(front_left)\n",
    "mod_front_right = PreProcess_DLC_data(front_right)\n",
    "mod_bot = PreProcess_DLC_data(bot)\n",
    "\n",
    "mod_front_left.to_csv('mod_front_left.csv', index=False)\n",
    "mod_front_right.to_csv('mod_front_right.csv', index=False)\n",
    "mod_bot.to_csv('mod_bot.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below which corresponds to your desired model to create the predictions based on your DeepLabCut data. Make sure you look at the pandas dataframe created to check whether or not your column labels match up between the dataframes from each camera view. Change num_cameras and bodyparts to the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 1:\n",
    "coordinatePath_1 = '/home/nel-lab/Documents/Behavior3D/Videos/model_1_coordinates.csv'\n",
    "#coordinatePath_1 = '/Applications/NoniCloud Desktop/GiovannucciLab/cal_images_2/model_1_coordinates.csv'\n",
    "m1_regr, X, Y, cv_predictions = Build_Model(coordinatePath_1)\n",
    "\n",
    "# Predicts real coordinates\n",
    "numCameras = 3\n",
    "bodyparts = 5\n",
    "\n",
    "mod_bot = pd.read_csv('mod_bot.csv')\n",
    "mod_bot = mod_bot.drop(mod_bot.columns[20:], axis=1)\n",
    "mod_front_right = pd.read_csv('mod_front_right.csv') \n",
    "mod_front_left = pd.read_csv('mod_front_left.csv') \n",
    "        \n",
    "m1_predictions = Predict_Real_Coordinates(mod_front_left, mod_front_right, \n",
    "                                          mod_bot, bodyparts, numCameras, m1_regr)\n",
    "\n",
    "# saves coordinates\n",
    "m1_Predictions = pd.DataFrame(m1_predictions)\n",
    "m1_Predictions.to_csv('m1_Predictions.csv', index=False)\n",
    "\n",
    "# plots bodyparts (300 frames, you can change this in the Plot_Bodyparts function)\n",
    "bodyparts = 5\n",
    "m1_Predictions = pd.read_csv('m1_Predictions.csv') \n",
    "m1_Predictions = m1_Predictions.to_numpy() \n",
    "Plot_Bodyparts(m1_Predictions, bodyparts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 2\n",
    "coordinatePath_2 = '/home/nel-lab/Desktop/WS_tests_for_DLC2/calibration2/model_2_coordinates.csv'\n",
    "m2_regr, X, Y, cv_predictions = Build_Model(coordinatePath_2)\n",
    "\n",
    "numCameras = 3\n",
    "bodyparts = 10\n",
    "\n",
    "mod_bot = pd.read_csv('mod_bot.csv') \n",
    "mod_back_left = pd.read_csv('mod_back_left.csv') \n",
    "mod_back_right = pd.read_csv('mod_back_right.csv') \n",
    "\n",
    "m2_predictions = Predict_Real_Coordinates(mod_back_left, mod_back_right, mod_bot,  \n",
    "                                          bodyparts, numCameras, m2_regr)\n",
    "\n",
    "m2_Predictions = pd.DataFrame(m2_predictions)\n",
    "m2_Predictions.to_csv('m2_Predictions.csv', index=False)\n",
    "\n",
    "\n",
    "bodyparts = 10\n",
    "m2_Predictions = pd.read_csv('m2_Predictions.csv') \n",
    "m2_Predictions = m2_Predictions.to_numpy() \n",
    "Plot_Bodyparts(m1_Predictions, bodyparts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2A\n",
    "coordinatePath_2a = '/home/nel-lab/Documents/Behavior3D/Videos/calibration_apr/model_2a_coordinates.csv'\n",
    "m2a_regr, X, Y, cv_predictions = Build_Model(coordinatePath_2a)\n",
    "\n",
    "\n",
    "numCameras = 2\n",
    "bodyparts = 5\n",
    "\n",
    "mod_bot = pd.read_csv('mod_bot.csv')\n",
    "mod_bot_l = mod_bot.drop(mod_bot.columns[20:], axis=1)\n",
    "mod_front_left = pd.read_csv('mod_front_left.csv') \n",
    "\n",
    "m2a_predictions = Predict_Real_Coordinates_2cam(mod_front_left, mod_bot_l, bodyparts, \n",
    "                                                numCameras, m2a_regr)\n",
    "\n",
    "m2a_Predictions = pd.DataFrame(m2a_predictions)\n",
    "m2a_Predictions.to_csv('m2a_Predictions.csv', index=False)\n",
    "\n",
    "\n",
    "bodyparts = 5\n",
    "m2a_Predictions = pd.read_csv('m2a_Predictions.csv') \n",
    "m2a_Predictions = m2a_Predictions.to_numpy() \n",
    "Plot_Bodyparts(m2a_Predictions, bodyparts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 2b\n",
    "coordinatePath_2b = '/home/nel-lab/Documents/Behavior3D/Videos/calibration_apr/model_2b_coordinates.csv'\n",
    "m2b_regr, X, Y, cv_predictions = Build_Model(coordinatePath_2b)\n",
    "\n",
    "numCameras = 2\n",
    "bodyparts = 5\n",
    "\n",
    "mod_bot = pd.read_csv('mod_bot.csv') \n",
    "mod_bot_r = mod_bot.drop(mod_bot.columns[10:], axis=1)\n",
    "mod_front_right = pd.read_csv('mod_front_right.csv') \n",
    "\n",
    "m2b_predictions = Predict_Real_Coordinates_2cam(mod_front_right, mod_bot_r, bodyparts, \n",
    "                                                numCameras, m2b_regr)\n",
    "\n",
    "m2b_Predictions = pd.DataFrame(m2b_predictions)\n",
    "m2b_Predictions.to_csv('m2b_Predictions.csv', index=False)\n",
    "\n",
    "bodyparts = 5\n",
    "m2b_Predictions = pd.read_csv('m2b_Predictions.csv') \n",
    "m2b_Predictions = m2b_Predictions.to_numpy() \n",
    "Plot_Bodyparts(m2b_Predictions, bodyparts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you've created the predictions (mn_Predictions.csv)! You can plot them or process them with data analysis, which can be found in William's 5th script, included in this repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
